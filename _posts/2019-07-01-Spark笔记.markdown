## 概述
核心概念是RDD，弹性分布式数据集，弹性体现在哪？

spark streaming就是一串rdd序列

## 核心架构
### 物理节点架构
- Master 接受客户端client提交的作业；管理worker，包括触发worker启动Driver和Executor。
- worker 运行application的节点。

### 抽象概念
- Driver （SparkContext）
    - Spark中的Driver即运行Application的main()函数并且创建SparkContext（创建SparkContext的目的是为了准备Spark应用程序的运行环境）。
    - SparkContext负责和ClusterManager通信，进行资源的申请、任务的分配和监控等；
    - 当Executor部分运行完毕后，Driver负责将SparkContext关闭。通常用SparkContext代表Driver。
- Executor application运行在worker节点上的进程
    - 把task包装成TaskRunner
    - 一个进程只有一个Executor对象，负责从线程池中取出空闲线程运行task。能并发几个task一般取决于cpu的核数

- Cluster Manager：指的是在集群上获取资源的外部服务，包括
    - Standalone：Spark原生的资源管理，由Master负责资源的分配；
    - Hadoop Yarn：由YARN中的ResourceManager负责资源的分配；
- Application 用户编写的spark程序

### DAG调度

- job 就是action算子（如count、collect）触发的整个RDD DAG，称为一个job；job的调度分为FIFO模式（先进先出）和FAIR模式（分配权重）。
- stage 根据是否shuffle来分每一个stage，就是DAG的每个节点；stage调度用广度优先遍历，每个stage一定要等到父stage调用结束。
- task 被送到executor上的工作任务。应该是窄依赖的算子，像filter等等；task的调度逻辑由TaskSetManager完成，整体的task分发由TaskSchedulerImpl来实现。

- TaskScheduler 实现Task分配到Executor上执行。
- DAGScheduler 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。

### 执行过程
![image](C0ACF9BFC7914D17AE1DE7E51EC09DA5)
master-slave模式
- 集群启动，每个slave向master注册，表示准备工作完成；master通过心跳机制集群的状态。
- driver提交作业的时候也向master注册
- master再向worker发送指令，每个worker生成executor
- executor向driver发送注册信息，driver分发作业，然后执行

## SparkSQL
DataFrame是有命名的一些列的dataSet，也可以说DataFrame是DataSet的别名。

## Spark Streaming
DStream (discretized stream)
a sequence of rdds




## 持久化 cache和presist



## 容错 
常用方法是**数据检查点**和**记录数据的更新**，而数据检查点要复制大量数据，带宽更不上  

### Lineage
spark用的是**记录数据的更新**， 类似于元数据的更新，要把操作保存下来。
spark可以通过lineage获得足够的信息来重新运算和恢复丢失的数据分区。
- 类似于数据库中的重做日志（redo log），Redis AOF也是这样。
- 但spark只能做到批量的、大粒度的。


### checkPoint机制
就是RDD写入磁盘作为检查点，作为lineage做容错的辅助，也可以作为持久化的工具。
方法**doCheckpoint()**，同步、Synchronized保证方法的同步和线程安全。

**场景**

1. 应用在如updateStateByKey这类状态算子。
2. 从失败状态中恢复

#### updateStateByKey 一种算子

返回一个新的DStream，通过给定的函数更新key的之前的状态和新value。
需要：
- 定义状态
- 定义状态更新函数 （151中AggregateMessage使用更新函数，执行了clean老数据、merge新数据操作）
```scala
def updateFunction(newValues: Seq[Int], runningCount: Option[Int]): Option[Int] = {
    val newCount = ...  // add the new values with the previous running count to get the new count
    Some(newCount)
}
val runningCounts = pairs.updateStateByKey[Int](updateFunction _)
```
**使用**

- 需要有一个持久化的目录
- 再从这个目录中生成StreamingContext
```scala
def functionToCreateContext(): StreamingContext = {
  val ssc = new StreamingContext(...)   // new context
  val lines = ssc.socketTextStream(...) // create DStreams
  ...
  ssc.checkpoint(checkpointDirectory)   // set checkpoint directory
  ssc
}

// Get StreamingContext from checkpoint data or create a new one
val context = StreamingContext.getOrCreate(checkpointDirectory, functionToCreateContext _)

// Do additional setup on context that needs to be done,
// irrespective of whether it is being started or restarted
context. ...

// Start the context
context.start()
context.awaitTermination()
```
这个例子持久化目录存在，则从目录恢复，没有则重新创建一个ssc

#### 项目实例

通用聚合计算app
1. 对每一条数据convert => (key, aggregatedMessage)
使用updateStateByKey，在TransformFunctions中进行。
2. 调用组件clean方法
3. 进行merge操作，加入新的message
4. 内存容器的大小检查，超过阈值则抛弃。
5. checkPoint备份
6. 调用evaluate

## scala和spark中的Actor

- Actor（主要处理并发）异步调用的抽象，通过消息来与外界以及其他Actor通信，一次只处理一个消息。
- spark的模块通信基于AKKA框架，可用于编写Actor应用，Actor通过消息来通信。


## Shuffle过程

narrow dependence：1个父RDD分区对应1个子RDD分区

shuffle dependence：1个父RDD分区对应多个子RDD分区

RDD经过transform和action形成新的RDD，其中transform分为窄依赖和宽依赖，宽依赖类似于MR的shuffle，窄依赖不需要改变内存的分配，直接在该节点的内存直接运行下一步。

### Shuffle Write
Task只分ShuffleMapTask和ResultTask，入口ShuffleMapTask的runTask方法
#### ShuffleWrite

- ShuffleWrite是抽象的Trait，一个具体实现是HashShuffleWrite。
- HashShuffleWrite：主要做要是提供主要shuffle write的主要流程，并且判断做普通shuffle还是MapSideCombine

#### 流程
1. 判断是否要需要在Map端做combine（聚集合并）
2. 在shuffleBlockManager做shuffle或者优化的Consolidate Shuffle
3. 把内存的Bucket写到磁盘。

**consolidate shuffle**

把mapper分为几批，后几批mapper产生的文件追加到第一批mapper写入的bucket后面。
其中，原来的shuffle的bucket数量为M\*R，现在是C*R，R <= C (C Core Number)

### Shuffle Fetch
就是reduce端拉取数据，两种方式：OIO通过socket去fetch数据，NIO通过Netty去fetch数据;通过元数据知道数据存储在哪个节点，从该节点拉去指定的key的数据。

### Shuffle Aggregator
分为需要外排的和不需要外排的，容器称为AppendOnlyMap，原理和HashMap一样，要动态扩容。
- 不需外排的就直接在内存做聚集
- 需要外排的，当内存达到阈值的时候，将数据排序写到磁盘，再将磁盘的数据合并和聚集。

## 其它
**map和mapPartitions的区别？**
1. map对每个元素进行操作，mapPartitions按分区进行迭代，例如，rdd有10个元素，对map进行f操作将调用10次，对mapPartitions进行f操作将调用3次（Partitions的数量）
2. mapPartitions需要对每个partition进行迭代，每个parition要用iterator。
3. 对于批处理来说，mapPartitions会有很大的优化，如数据库连接，mapPartitions只要连3次。
4. mapPartitions里的每个partition也是个rdd，也可以调用map、flatmap等算子。

**reduceByKey和groupByKey的区别**？
- groupByKey比较耗费资源
- groupByKey是将key相同的元素聚合在一起（（a,1）,(a,2)）),((b,1),(b,2),(b,3))
- 如下效果是一致的，但reduceByKey会在**每个分区**先进行求和，而groupByKey会先把所有元素聚合再一起求和
```scala
reduceByKey（\_+\_）

groupByKey（）.map(t => (t.\_1, t._2.sum))
```

**其他要点**
1. spark与MR相比，主要减少了磁盘的I/O，整个过程不需要落地（当然内存不足的节点还是要把部分数据存在磁盘）。
2. rdd都是从头开始计算的，cache和prisist都可以将中间数据持久化，减少重复计算。
3. 每个rdd是可容错的，这是很重要的一点。